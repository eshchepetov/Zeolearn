---------------------------------------------------------------------------------------------------------------------
17/11/24 22:26:45 INFO mapreduce.Job:  map 0% reduce 0%
17/11/24 22:26:51 INFO mapreduce.Job: Task Id : attempt_1511557707801_0003_m_000000_0, Status : FAILED
Error: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.DoubleWritable, received org.apache.hadoop.io.IntWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1097)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:724)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.eugene.zeolearn.mrtask.AverageTempMapper.map(AverageTempMapper.java:26)
	at org.eugene.zeolearn.mrtask.AverageTempMapper.map(AverageTempMapper.java:14)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:796)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

---------------------------------------------------------------------------------------------------------------------
[hadoop@ip-172-31-17-229 ~]$ hadoop jar test.jar input output
17/11/24 23:15:33 INFO impl.TimelineClientImpl: Timeline service address: http://ip-172-31-17-229.ec2.internal:8188/ws/v1/timeline/
17/11/24 23:15:33 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-17-229.ec2.internal/172.31.17.229:8032
17/11/24 23:15:33 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
17/11/24 23:15:33 WARN hdfs.DFSClient: Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:609)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:370)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:546)
17/11/24 23:15:33 INFO input.FileInputFormat: Total input paths to process : 2
17/11/24 23:15:33 INFO lzo.GPLNativeCodeLoader: Loaded native gpl library
17/11/24 23:15:33 INFO lzo.LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev d73c901b4228f4e75d3a527ec2318ce7376036cb]
17/11/24 23:15:34 INFO mapreduce.JobSubmitter: number of splits:2
17/11/24 23:15:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1511557707801_0005
17/11/24 23:15:34 INFO impl.YarnClientImpl: Submitted application application_1511557707801_0005
17/11/24 23:15:34 INFO mapreduce.Job: The url to track the job: http://ip-172-31-17-229.ec2.internal:20888/proxy/application_1511557707801_0005/
17/11/24 23:15:34 INFO mapreduce.Job: Running job: job_1511557707801_0005
17/11/24 23:15:42 INFO mapreduce.Job: Job job_1511557707801_0005 running in uber mode : false
17/11/24 23:15:42 INFO mapreduce.Job:  map 0% reduce 0%
17/11/24 23:15:53 INFO mapreduce.Job:  map 100% reduce 0%
17/11/24 23:15:59 INFO mapreduce.Job:  map 100% reduce 100%
17/11/24 23:16:00 INFO mapreduce.Job: Job job_1511557707801_0005 completed successfully
17/11/24 23:16:00 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=29205
		FILE: Number of bytes written=439983
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1777426
		HDFS: Number of bytes written=48
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=865872
		Total time spent by all reduces in occupied slots (ms)=351840
		Total time spent by all map tasks (ms)=18039
		Total time spent by all reduce tasks (ms)=3665
		Total vcore-milliseconds taken by all map tasks=18039
		Total vcore-milliseconds taken by all reduce tasks=3665
		Total megabyte-milliseconds taken by all map tasks=27707904
		Total megabyte-milliseconds taken by all reduce tasks=11258880
	Map-Reduce Framework
		Map input records=13130
		Map output records=13130
		Map output bytes=118170
		Map output materialized bytes=29158
		Input split bytes=258
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=29158
		Reduce input records=13130
		Reduce output records=2
		Spilled Records=26260
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=507
		CPU time spent (ms)=2840
		Physical memory (bytes) snapshot=1074307072
		Virtual memory (bytes) snapshot=11166691328
		Total committed heap usage (bytes)=977797120
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters
		Bytes Read=1777168
	File Output Format Counters
		Bytes Written=48
Result:0
[hadoop@ip-172-31-17-hadoop fs -ls output
Found 2 items
-rw-r--r--   1 hadoop hadoop          0 2017-11-24 23:15 output/_SUCCESS
-rw-r--r--   1 hadoop hadoop         48 2017-11-24 23:15 output/part-r-00000
[hadoop@ip-172-31-17-229 ~]$ hadoop fs -cat output/part-r-00000
1901	48.214470677837014
1902	21.659558263518658
[hadoop@ip-172-31-17-229 ~]$

